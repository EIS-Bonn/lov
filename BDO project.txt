Installation of Elasticsearch 1.3.1 docker
	1. Download zip file from 
	https://github.com/kpearsondx/docker-elasticsearch
	2. Unzip folder
	3. Go to Dockerfile and change
		a. Line 4: openjdk-8-jre-headless or newer
		b. Line 5: â€¦/java-8-openjdk-amd64
	4. Open a terminal and type one by one
		a. docker build . -t elasticsearch
		b. docker run -d -v "$PWD/config":/usr/share/elasticsearch/config elasticsearch
		c. docker run -d -v "$PWD/esdata":/usr/share/elasticsearch/data elasticsearch
		d. docker run -v /usr/share/elasticsearch/data -p 9200:9200 -e "http.host=0.0.0.0" -e "transport.host=127.0.0.1" elasticsearch

Installation of necessary software
	1. Node.js 
	https://tecadmin.net/install-latest-nodejs-npm-on-ubuntu/# 
	Open a terminal
		a. sudo apt-get install python-software-properties
		b. curl -sL https://deb.nodesource.com/setup_6.x | sudo -E bash -
		c. sudo apt-get install nodejs

	2. MongoDB
	https://docs.mongodb.com/manual/tutorial/install-mongodb-on-ubuntu/
		a. sudo apt-key adv --keyserver hkp://keyserver.ubuntu.com:80 --recv 0C49F3730359A14518585931BC711F9BA15703C6
		b. For Ubuntu 16.04
		echo "deb [ arch=amd64,arm64 ] http://repo.mongodb.org/apt/ubuntu xenial/mongodb-org/3.4 multiverse" | sudo tee /etc/apt/sources.list.d/mongodb-org-3.4.list
		c. sudo apt-get update
		d. sudo apt-get install -y mongodb-org
		e. Start mongoDB service
		sudo service mongod start
		f. To automatically start mongoDB:
		sudo systemctl enable mongod.service
	
	3. Maven
	sudo apt install maven

Lov and LovScripts projects for BigDataOcean
https://github.com/EIS-Bonn/lov
https://github.com/EIS-Bonn/lovScripts

	1. Lov (Frontend)
		a. Go to the path you want to save the project
		git clone https://github.com/EIS-Bonn/lov.git
		b. Go to lov/config and change: 
			i. configPath.js to the path where the projects (lov and lovScripts) are saved and the mail that it is going to be used for notifications.
			ii. config.js to change the user and pass of the authentication
		c. Go to lov/public and unzip bdo.zip
		d. Go to lov/setup/BDO_setup
			i. Open a terminal and 
			mongoimport -d bdo -c agents --file agents.json
			mongoimport -d bdo -c languages --file languages.json
			mongoimport -d bdo -c logsearches --file logsearches.json
			mongoimport -d bdo -c sessions --file sessions.json
			mongoimport -d bdo -c statlanguages --file statlanguages.json
			mongoimport -d bdo -c stattags --file stattags.json
			mongoimport -d bdo -c statvocabularies --file statvocabularies.json
			mongoimport -d bdo -c users --file users.json
			mongoimport -d bdo -c vocabularies --file vocabularies.json
		d. Go to lov/setup and unzip versions.zip, move the folder to the location of /lov/
		e. Open a terminal
		npm install
	
	2. LovScripts (Backend)
		a. Go to the same path as LOV
		git clone https://github.com/EIS-Bonn/lovScripts.git
		b. Go to /lovScripts/src/main/resources/log4j.properties 
		create folders scripts/log and file server.log in /root/Documents/BigDataOcean/
		and modify the line 15, to the path created before
		c. Go to /lovScripts/lov.config
		And modify all PATHs (LOV_NQ_FILE_PATH, LOV_RDF_FILE_PATH, LOV_N3_FILE_PATH, METRICS_FILE_PATH, VERSIONS_DIR_PATH, VERSIONS_TEMP_PATH)
		d. Go to lovScripts/src/main/java/org/lov/cli/configPath.java
		Change the path to the lov.config file
		e. Open a terminal: cd Documents/BigDataOcean/lovScripts
		mvn install
		f. Open a terminal and (ElasticSearch docker must be running)
		cd Documents/BigDataOcean/lovScripts/target/lovscripts-cli/lovscripts/bin then
			i. ./create-index 
			ii. ./index-lov

SPARQL Endpoint
https://jena.apache.org/documentation/serving_data/
	1. Go to https://jena.apache.org/download/index.cgi
	2. Download apache-jena-fuseki-2.6.0.zip
	3. Unzip and open a terminal
	4. Go to the path where the zip file was unzipped
		a. chmod +x fuseki-server
		b. ./fuseki-server --update --mem /bigdataocean
	5. Go to localhost:3030
	6. Select "add data" button
	7. Select lov.nq and lov.n3 files from /root/Documents/BigDataOcean/lov/public and upload them

Running BigDataOcean Repository
	1. Open a terminal (do not close it)
		a. Start elasticsearch docker with volume
		docker run -v /usr/share/elasticsearch/data -p 9200:9200 -e "http.host=0.0.0.0" -e "transport.host=127.0.0.1" elasticsearch
	2. Open another terminal (do not close it)
		a. ./fuseki-server --update --mem /bigdataocean
		b. Go to localhost:3030
	       Select "add data" button
	       Select lov.nq and lov.n3 files from /root/Documents/BigDataOcean/lov/public and upload them
	3. Open another terminal (do not close it)
		a. If mongodb does not start automatically; Start mongo service
		sudo service mongod start
		b. cd Documents/BigDataOcean/lov
		npm start
	4. Go to google chrome and http://localhost:3333/dataset/bdo

NOTE:
In order to work with the new web server, we change some information:
	1. LovScripts: 
		- LovConstants.java line 19, 41 we change localhost to 212.101.173.34
		- lov.config line 8

	2. Lov:
		- views/api.jade all the line that contain localhost we change it to 212.101.173.34
		- views/endpoint/index.jade line 34
		- config/configPath.js line 9
		- config/routes.js line 259
		- setup/BDO_setup/vocabularies.json in each line that has localhost was changed to 212.101.173.34
		- in order to see the changes in fuseki, we run the mongo2rdf bash to create .n3 and .nq that are save in the public/bdo.zip